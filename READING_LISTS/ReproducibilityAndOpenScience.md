This list is adapted from Lucia Magis Weinberg's [list of resources for getting started with open science and reproducibility](https://luciamagisweinberg.wordpress.com/2017/03/23/reproducibilityopen-science-resources/). Thank you Lucia :sparkles: :tada:

### Overviews and timelines of the "Reproducibility Crisis"

Wagenmakers, E.-J. (2015). [A perfect storm: The record of a revolution](http://www.in-mind.org/article/a-perfect-storm-the-record-of-a-revolution). In-Mind Magazine.

[Replicability and Reproducibility Debate](http://www.bps.org.uk/what-we-do/bps/governance/boards-and-committees/research-board/research-board-resources/replicability-and-reproducibility-debate/replicability-and-reproducibility-debate) (2016) organized by the BPS at the Royal Society with presentations from Marcus Munafò, Roger Watt, Dorothy Bishop, Chris Chambers, Kathryn Sharples, Nick Brown and Prateek Buch. [video](https://www.youtube.com/watch?v=tTuZ-IEc0Eg&feature=youtu.be)

Bastian, H. (2016). [Reproducibility Crisis Timeline: Milestones in Tackling Research Reliability](http://blogs.plos.org/absolutely-maybe/2016/12/05/reproducibility-crisis-timeline-milestones-in-tackling-research-reliability/).

Gelman, A. (2016). [What has happened down here is the winds have changed](http://andrewgelman.com/2016/09/21/what-has-happened-down-here-is-the-winds-have-changed/) .


### Examination of mistakes that distort research

Slides by Tom Hardwicke. Science as a Human Edeavour/ Building a Reproducible Research Workflow [[Slides](https://osf.io/rxwsp/)]. 

FiveThirtyEight’s [Hack Your Way To Scientific Glory](https://projects.fivethirtyeight.com/p-hacking/) 


### Statistical discussion of the expected frequency of false positives

Ioannidis JP (2005) Why most published research findings are false. PLoS Med 2: e124. [doi:10.1371/journal.pmed.0020124](https://doi.org/10.1371/journal.pmed.0020124)

Leek, Jeffrey T. and Jager, Leah R., Is Most Published Research Really False? (March 2017). Annual Review of Statistics and Its Application, Vol. 4, Issue 1, pp. 109-122, 2017. [doi:10.1146/annurev-statistics-060116-054104](http://doi.org/10.1146/annurev-statistics-060116-054104)

Open Science Collaboration. (2015). Science, 349(6251). [Estimating the reproducibility of psychological science](https://osf.io/ezum7/). 


### Better research practices 

Slides by Courtney Soderberg. Practical Steps for Increasing Openness and Reproducibility. [[Slides](https://osf.io/br8d4/)]. 

Hardwicke, T. E., Jameel, L., Jones, M., Walczak, E. J., & Magis-Weinberg, L. (2014). Only human: Scientists, systems, and suspect statistics. Opticon1826, (16):25, 1-12. [doi:10.5334/opt.ch](http://dx.doi.org/10.5334/opt.ch) [pdf](http://www.tomhardwicke.co.uk/docs/onlyHuman.pdf). 

Chambers, C. D., Dienes, Z., McIntosh, R. D., Rotshtein, P. and Willmes, K. (2015). Registered reports: realigning incentives in scientific publishing. Cortex, 66, A1-A2. [doi:10.1016/j.cortex.2015.03.022](http://dx.doi.org/10.1016/j.cortex.2015.03.022)

Morey, R. D., Chambers, C. D., Etchells, P. J., Harris, C. R., Hoekstra, R., Lakens, D., Lewandowsky, S., Morey, C. C., Newman, D. P., Schönbrodt, F. D., Vanpaemel, W., Wagenmakers, E. and Zwaan, R. A. (2016). The Peer Reviewers’ Openness Initiative: incentivizing open research practices through peer review. Royal Society Open Science, 3(1). [doi:10.1098/rsos.150547](http://doi.org/10.1098/rsos.150547)

Munafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Percie du Sert, N., Simonsohn, U., Wagenmakers, E.-J., Ware, J. J., & Ioannidis, J. P. A. (in press). A manifesto for reproducible science. Nature Human Behaviour. [doi:10.1038/s41562-016-0021](https://doi.org/10.1038/s41562-016-0021).

Taschuk M, Wilson G (2017) Ten simple rules for making research software more robust. PLoS Comput Biol 13(4): e1005412. [doi:10.1371/journal.pcbi.1005412](https://doi.org/10.1371/journal.pcbi.1005412)

PLoS Collection: ["Ten simple rules"](http://collections.plos.org/ten-simple-rules)

